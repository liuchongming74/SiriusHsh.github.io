---
layout: post
title:  Ng机器学习--课程笔记（七）
categories: 学习笔记 机器学习
tags: 机器学习
author: HSH
mathjax: true
---

* content
{:toc}


# Evaluating a learning algorithm/Machine learning diagnostic
在机器学习中会遇到一些训练效果不好的情况，如何衡量算法的好坏，以及如何改进，是很关键的问题。  
Ng给出了如图所示的一些方法，但是总不能全试吧，浪费时间，于是提出了“诊断”的概念。  
![lesson7-1.png](http://octtw77pk.bkt.clouddn.com//public/upload/lesson7-1.png) 







## 1.评价假设函数
很传统的方法，将数据集73分，7成作为训练集，3成作为测试集。用训练集训练得到惩罚参数，带入到损失函数中，用测试集进行计算，得到损失总和。  
>对于线性回归：  
>![lesson7-2.png](http://octtw77pk.bkt.clouddn.com//public/upload/lesson7-2.png)   

>对于逻辑回归：  
>![lesson7-5.png](http://octtw77pk.bkt.clouddn.com//public/upload/lesson7-5.png)  
>或者
>![lesson7-3.png](http://octtw77pk.bkt.clouddn.com//public/upload/lesson7-3.png)     
>![lesson7-4.png](http://octtw77pk.bkt.clouddn.com//public/upload/lesson7-4.png)    

## 2.模型选择
假设函数应该用几次的多项式，什么是正确的特征，正则化参数$\lambda$如何选择？这些都是模型选择的问题。  
道理很简单，为了避免做出测试集来进行模型选择这种事情，我们将数据集划分为三块，622分是经典的分割方法，6成作为训练集，2成作为验证集，2成作为测试集。拿验证集出来，对模型进行评估，选出效果最好的那个模型，然后用测试集对该模型进行测试。 

## 3.偏差还是方差？
![lesson7-6.png](http://octtw77pk.bkt.clouddn.com//public/upload/lesson7-6.png)  
如图所示，左边框框处于欠拟合状态，此时$J_{train}(\theta)$ 和 $J_{CV}(\theta)$都很大，且两值接近。  右边框框处于过拟合状态，此时$J_{train}(\theta)$很小，$J_{CV}(\theta)$很大，两值差值很大。  

此时去考虑正则化参数$\lambda$，就很容易理解，当$\lambda$越大，越接近欠拟合。于是有了下图：  
![lesson7-7.png](http://octtw77pk.bkt.clouddn.com//public/upload/lesson7-7.png)

## 4.学习曲线
学习曲线可以很好的帮助我们判断，目前是处于高偏差还是高方差阶段。  
>高偏差  看似$J_{train}(\theta)$ 和 $J_{CV}(\theta)$很接近，但是然并软，无论数据量有多大，error永远处于比较大的阶段。  所以再增加数据量也是徒劳。  
>![lesson7-8.png](http://octtw77pk.bkt.clouddn.com//public/upload/lesson7-8.png)


>高方差 看起来增加数据量还是有点用的。当数据量很大很大时，$J_{train}(\theta)$ 和 $J_{CV}(\theta)$会越来越接近，并且error趋于一个可接受的大下。  
>![lesson7-9.png](http://octtw77pk.bkt.clouddn.com//public/upload/lesson7-9.png)  

## 5.总结
![lesson7-10.png](http://octtw77pk.bkt.clouddn.com//public/upload/lesson7-10.png)

# 构造机器学习系统的一些建议
## 1.error analysis（误差分析）
![lesson7-14.png](http://octtw77pk.bkt.clouddn.com//public/upload/lesson7-14.png)  
感觉这个实现的流程很适合应用于kaggle这类机器学习比赛中。  
误差分析，说白了就是人工去分析，拿垃圾邮件分类问题来说，去看看验证集中哪些邮件总是被分类错误，通过大量的统计，能够找到规律，然后可以去构造新的特征。

研究下图这个实例
![lesson7-15.png](http://octtw77pk.bkt.clouddn.com//public/upload/lesson7-15.png)  通过对错误样本的分析，从而更好的构造特征变量。
Ng强调尽量保证在**交叉验证集**上做

## 2.skewed classes（偏斜类）
有的时候正负样本严重倾斜，比如在癌症检测事件中，真实患有癌症的样例占了0.5%，我们通过机器学习算法，得到了99%的准确率，但是这也意味着有1%的错误率。当我们构建这样一种算法，它也已经称不上是机器学习算法了，它总是返回(y = 0)，即诊断所有人都没有患癌症，这种算法错误率居然只有0.5%。比我们辛辛苦苦构建的机器学习算法的准确率还高。这就是一种偏斜类的体现，对于这类样本，我们需要引进另外两种判断方法，即precision和recall (查准率)/(召回率)。  
![lesson7-16.png](http://octtw77pk.bkt.clouddn.com//public/upload/lesson7-16.png)  
![lesson7-17.png](http://octtw77pk.bkt.clouddn.com//public/upload/lesson7-17.png)  

### 对查准率和召回率的评判标准
![lesson7-20.png](http://octtw77pk.bkt.clouddn.com//public/upload/lesson7-20.png) 通过对阈值的设置，能够在召回率和查准率之间进行抉择。当阈值很高时，能够获得很高的查准率，但是召回率就很低。  
一种衡量标准是F值：  
![lesson7-19.png](http://octtw77pk.bkt.clouddn.com//public/upload/lesson7-19.png)  
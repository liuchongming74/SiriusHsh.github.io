<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>nEver Enough</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-04-08T08:22:05.219Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>SiriusHsh</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>从零开始的毕设-深入MNIST</title>
    <link href="http://yoursite.com/2017/04/06/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E6%AF%95%E8%AE%BE-%E6%B7%B1%E5%85%A5MNIST/"/>
    <id>http://yoursite.com/2017/04/06/从零开始的毕设-深入MNIST/</id>
    <published>2017-04-06T14:52:20.000Z</published>
    <updated>2017-04-08T08:22:05.219Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://octtw77pk.bkt.clouddn.com/daolu.jpg" alt="enter description here"></p>
<a id="more"></a>
<blockquote>
<p>本文要点：我将学习到构建一个TensorFlow模型的基本步骤，并将通过这些为MNIST构建一个深度卷积神经网络。</p>
</blockquote>
<p><strong>安装</strong><br>在创建模型之前，我们会先加载MNIST数据集，然后启动一个TensorFLow的session</p>
<p><strong>加载MNIST数据</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow.examples.tutorials.mnist.input_data <span class="keyword">as</span> input_data</div><div class="line">mnist = imput_data.read_data_sets(<span class="string">'MNIST_data'</span>, one_hot=<span class="keyword">True</span>)</div></pre></td></tr></table></figure>
<p>这里，mnist是一个轻量级的类。它以Numpy数组的形式存储着训练、校验和测试数据集。同时提供一个函数，用于在迭代中获得minibatch，后面我们将会用到</p>
<p><strong>运行TensorFlow的InteractiveSession</strong><br>TensorFlow依赖于一个高效的C++后端来进行计算，与后端的这个连接叫做session，一般而言，使用TensorFlow程序的流程是先创建一个图，然后在session中启动它。</p>
<p>这里，我们使用更加方便的<code>InteractiveSession</code>类。通过它，你可以更加灵活地构建代码。它能让你在运行图的时候，插入一些计算图，这些计算图是由某些操作(op)构成的。这对于工作在交互式环境中的人们来说非常便利，比如使用IPython。如果你没有使用InteractiveSession，那么你需要在启动session之前构建整个计算图，然后启动该计算图。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line">sess = tf.InteractiveSession()</div></pre></td></tr></table></figure></p>
<p><strong>构建Softmax回归模型</strong><br>在这一节中我们将建立一个拥有一个线性层的softmax回归函数。在下一个，我们会将其扩展成一个拥有多层卷积网络的softmax回归函数</p>
<p><strong>占位符</strong><br>我们通过为输入图像和目标输出类别创建节点，来开始构建计算图。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">x = tf.placeholder(&quot;float&quot;, shape=[None,784])</div><div class="line">y_ = tf.placeholder(&quot;float&quot;, shape=[None, 10])</div></pre></td></tr></table></figure></p>
<p>这里的x和y并不是特定值，他们只是一个占位符，可以再TensorFlow运行某一计算时根据该占位符输入具体的值。<br>输入图片x是一个2维的浮点数张量，这里，分配给它shape为[None， 784]，其中784是一张展平的MNIST图片的维度。None表示其值大小不定。在这里作为第一个维度值，用以指代batch的大小，意即x的数量不定。输出类别值y_也是一个2维张量，其中每一行为一个10维的one-ho向量，用于代表对应某个MNIST图片的类别。<br>虽然placeholder的shape参数是可选的，但有了它，TensorFlow能够自动捕捉因数据维度不一致导致的错误。</p>
<p><strong>变量</strong><br>我们现在为模型定义权重W和偏置b。可以将它们当做额外的输入量，但是TensorFlow有一个更好的处理方式：变量。<br>一个变量代表着TensorFlow计算图中的一个值，能够在计算过程中使用，甚至修改。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">W = tf.Variable(tf.zeros([784, 10]))</div><div class="line">b = tf.Variable(tf.zeros([10]))</div></pre></td></tr></table></figure></p>
<p>我们在调用<code>tf.Variable</code>的时候传入初始值 零向量。W是一个784*10的矩阵（因为我们有784个特征和10个输出值）。b是一个10维的向量（因为我们有10个分类）<br>变量需要通过session初始化后，才能在session中使用。这一初始化步骤，为初始值指定具体指，并将其分配给每个变量，可以一次性为所有变量完成此操作。<br><code>sess.run(tf.initialize_all_variables())</code></p>
<p><strong>类别预测与损失函数</strong><br>现在可以实现我们的回归函数了，这只需要一行。我们把向量化后的图片x和权重矩阵W相乘，再加上偏置b，然后计算每个分类的softmax概率值。<br><code>y = tf.nn.softmax(tf.matmul(x,W) + b)</code><br>可以很容易的为训练过程指定最小化误差用的损失函数，我们的损失函数是目标类别和预测类别之前的交叉熵。<br><code>cross_entropy = -tf.reduce_sum(y_ * tf.log(y))</code><br>注意，<code>tf.reduce_sum</code>把minibatch里的每张图片的交叉熵都加起来了，我们计算的交叉熵是指整个minibatch。</p>
<p><strong>训练模型</strong><br>我们已经定义好模型和训练用的损失函数，那么用TensorFlow进行训练就很简单了。因为TensorFlow知道整个计算图，它可以使用自动微分法找到对于各个变量的损失的梯度值。TensorFlow有大量内置的优化算法，这里这例子中，我们用最速下降法让交叉熵下降，步长为0.01.<br><code>train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)</code><br>这一行代码实际上是用来计算图上添加一个新操作，其中包括计算梯度，计算每个参数的步长变化，并且计算出新的参数值。</p>
<p>返回的train_step操作对象，在运行时会使用梯度下降来更新参数。因此，整个模型的训练可以通过反复地运行train_step来完成。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">for i in range(1000)</div><div class="line">	batch = mnist.train.next_batch(50)</div><div class="line">	train_step.run(feed_dict=&#123;x: batch[0], y_: batch[1]&#125;)</div></pre></td></tr></table></figure></p>
<p>每一步迭代，我们都会加载50个训练样本，然后执行一次train_step，并通过feed<em>dict将x和y</em>张量占位符用训练数据代替。</p>
<p><strong>评估模型</strong><br>那么我们的模型的性能如何呢？<br>首先让我们找出那些预测正确的标签。tf.argmax是一个非常有用的函数，它能给出某个tensor对象在某一维上的其数据最大值所在的索引。由于标签向量是由0,1组成，因此最大值1所在的索引位置就是类别标签，比如tf.argmax(y, 1)返回的是模型对于任一输入x预测到的标签值，而tf.argmax(y_, 1)代表正确的标签，我们可以用tf.equal来检测我们的预测是否真实标签屁匹配。<br><code>correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))</code><br>这里返回一个布尔数组，为了计算我们分类的准确率，我们将布尔值转换为浮点数来代表对、错，然后去平均值。例如:[True, False, True, True]<br>变成[1,0,1,1]，计算出平均值为0.75<br><code>accuracy = tf.reduce_mean(tf.cast(correct_prediction, &quot;float&quot;))</code><br>最后，我们可以计算出在测试数据上的准确率，大概为91%<br><code>print accuracy.eval(feed_dict = {x: mnist.test.images, y_: mnist.test.labels})</code></p>
<p><strong>构建一个多层卷积网络</strong><br>目标：99.2%正确率</p>
<p><strong>权重初始化</strong><br>为了创建这个模型，我们需要创建大量的权重和偏置项。这个模型中的权重在初始化时应该加入少量的噪声来打破对称性以及避免0梯度。由于我们使用的是ReLU神经元，因此比较好的做法是用一个较小的正数来初始化偏置项，以避免神经元节点输出恒为0的问题。为了不在建立模型的时候反复做初始化操作，我们定义两个函数用于初始化。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">def weight_variable(shape):</div><div class="line">	initial = tf.truncated_normal(shape, stddev=0.1)</div><div class="line">	return tf.Variable(initial)</div><div class="line"></div><div class="line">def bias_variable(shape):</div><div class="line">	initial = tf.constant(0.1, shape=shape)</div><div class="line">	return tf.Variable(initial)</div></pre></td></tr></table></figure></p>
<p><strong>卷积和池化</strong><br>TensorFlow在卷积和池化上有很强的灵活性。我们怎么处理边界？步长应该设多大？在这个实例里，我们会一直使用vanilla版本。我们的卷积使用1步长（stride size）,0边距（padding size）的模板，保证输出和输入是同一个大小。我们的池化用简单传统的2*2大小的模板做max pooling。为了代码更简洁，我们把这部分抽象成一个函数。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">def conv2d(x, W):</div><div class="line">	return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding = &apos;SAME&apos;)</div><div class="line"></div><div class="line">def max_pool_2x2(x):</div><div class="line">	return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding = &apos;SAME&apos;)</div></pre></td></tr></table></figure></p>
<p><strong>第一层卷积</strong><br>现在我们可以开始实现第一层了。它由一个卷积接一个max pooling完成。卷积在每个5*5的patch中算出32个特征。卷积的权重张量形状是[5, 5, 1, 32]，前两个维度是patch的大小，接着是输入的通道数目，最后是输出的通道数目。而对于每一个输出通道都有一个对应的偏置量。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">W_conv1 = weight_variable([5, 5, 1, 32])</div><div class="line">b_conv1 = bias_variable([32])</div></pre></td></tr></table></figure></p>
<p>为了用这一层，我们把x变成一个4d向量，其第2、第3维对应图片的宽、高，最后一维代表图片的颜色通道数（因为是灰度图所以这里的通道数为1，如果是rgb彩色图，则为3）<br><code>x_image = tf.reshape(x, [-1, 28, 28, 1])</code><br>我们把x_image的权值向量进行卷积，加上偏置项，然后应用ReLU激活函数，最后进行max pooling。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)</div><div class="line">h_pool1 = max_pool_2x2(h_conv1)</div></pre></td></tr></table></figure></p>
<p>第二层卷积<br>为了构建一个更深的网络，我们会把几个类似的层堆叠起来。第二层中，每个5X5的patch会得到64个特征。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">W_conv2 = weight_variable([5, 5, 32, 64])</div><div class="line">b_conv2 = bias_variable([64])</div><div class="line"></div><div class="line">h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)</div><div class="line">h_pool2 = max_pool_2x2(h_conv2)</div></pre></td></tr></table></figure></p>
<p><strong>密集连接层</strong><br>现在，图片尺寸减小到7*7，我们加入一个有1024个神经元的全连接层，用于处理整个图片。我们把池化层输出的张量reshape成一些向量，乘上权重矩阵，加上偏置，然后对其使用ReLU。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">W_fc1 = weight_variable([7 * 7 * 64, 1024])</div><div class="line">b_fc1 = bias_variable([1024])</div><div class="line"></div><div class="line">h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])</div><div class="line">h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)</div></pre></td></tr></table></figure></p>
<p><strong>Dropout</strong><br>为了减少过拟合，我们在输出层以前加入dropout。我们用一个placeholder来代表一个神经元的输出在dropout中保持不变的概率。这样我们可以在训练过程中启用启动dropout，在测试过程中关闭dropout。TensorFlow的tf.nn.dropout操作除了可以屏蔽神经元的输出外，还会自动处理神经元输出值的scale。所以用dropout的时候可以不用考虑scale。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">keep_prob = tf.placeholder(&quot;float&quot;)</div><div class="line">h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)</div></pre></td></tr></table></figure></p>
<p><strong>输出层</strong><br>最后，我们添加一个softmax层，就像前面的单层softmax regression一样。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">W_fc2 = weight_variable([1024, 10])</div><div class="line">b_fc2 = bias_variable([10])</div><div class="line"></div><div class="line">y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)</div></pre></td></tr></table></figure></p>
<p><strong>训练和评估模型</strong><br>这个模型的效果如何呢?</p>
<p>为了进行训练和评估，我们使用与之前简单的单层softmax神经网络模型几乎相同的一套代码，只是我们会用更加复杂的ADAM优化器来做梯度最速下降，在feed_dict中加入额外的参数keep_prob来控制dropout比例。然后每100次迭代输出一次日志。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))</div><div class="line">train_step = tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(cross_entropy) </div><div class="line">correct_prediction = tf.equal(tf.argmax(y_conv, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</div><div class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))</div><div class="line">sess.run(tf.initialize_all_variables())</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20000</span>):</div><div class="line">	batch = mnist.train.next_batch(<span class="number">50</span>)</div><div class="line">	<span class="keyword">if</span> i%<span class="number">100</span> == <span class="number">0</span>:</div><div class="line">		train_accuracy = accuracy.eval(feed_dict = &#123;</div><div class="line">		x:batch[<span class="number">0</span>], y_:batch[<span class="number">1</span>], keep_prob: <span class="number">1.0</span>&#125;)</div><div class="line">		print(<span class="string">"step %d, training accuracy %g"</span> %(i, train_accuracy))</div><div class="line">	train_step.run(feed_dict=&#123;x: batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>], keep_prob: <span class="number">0.5</span>&#125;)</div><div class="line"></div><div class="line">print(<span class="string">"test accuracy %g"</span> %accuracy.eval(feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels, keep_prob: <span class="number">1.0</span>&#125;))</div></pre></td></tr></table></figure></p>
<p>在最终测试集上的准确率大概是99.2%。</p>
<p>代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow.examples.tutorials.mnist.input_data <span class="keyword">as</span> input_data</div><div class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data/"</span>,one_hot=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line">sess = tf.InteractiveSession()</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape)</span>:</span></div><div class="line">    initial = tf.truncated_normal(shape, stddev = <span class="number">0.1</span>)</div><div class="line">    <span class="keyword">return</span> tf.Variable(initial)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape)</span>:</span></div><div class="line">    initial = tf.constant(<span class="number">0.1</span>, shape = shape)</div><div class="line">    <span class="keyword">return</span> tf.Variable(initial)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, W)</span>:</span></div><div class="line">    <span class="keyword">return</span> tf.nn.conv2d(x, W, strides = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding = <span class="string">'SAME'</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_2x2</span><span class="params">(x)</span>:</span></div><div class="line">    <span class="keyword">return</span> tf.nn.max_pool(x, ksize = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding = <span class="string">'SAME'</span>)</div><div class="line"></div><div class="line">x = tf.placeholder(<span class="string">"float"</span>, [<span class="keyword">None</span>, <span class="number">784</span>])</div><div class="line">y_ = tf.placeholder(<span class="string">"float"</span>, [<span class="keyword">None</span>,<span class="number">10</span>])</div><div class="line"></div><div class="line">W_conv1 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">32</span>])</div><div class="line">b_conv1 = bias_variable([<span class="number">32</span>])</div><div class="line"></div><div class="line">x_image = tf.reshape(x, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span> ,<span class="number">1</span>])</div><div class="line"></div><div class="line">h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)</div><div class="line">h_pool1 = max_pool_2x2(h_conv1)</div><div class="line"></div><div class="line">W_conv2 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">64</span>])</div><div class="line">b_conv2 = bias_variable([<span class="number">64</span>])</div><div class="line"></div><div class="line">h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)</div><div class="line">h_pool2 = max_pool_2x2(h_conv2)</div><div class="line"></div><div class="line">W_fc1 = weight_variable([<span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>, <span class="number">1024</span>])</div><div class="line">b_fc1 = bias_variable([<span class="number">1024</span>])</div><div class="line"></div><div class="line">h_pool2_flat = tf.reshape(h_pool2, [<span class="number">-1</span>, <span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>])</div><div class="line">h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)</div><div class="line"></div><div class="line">keep_prob = tf.placeholder(<span class="string">"float"</span>)</div><div class="line">h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)</div><div class="line"></div><div class="line">W_fc2 = weight_variable([<span class="number">1024</span>, <span class="number">10</span>])</div><div class="line">b_fc2 = bias_variable([<span class="number">10</span>])</div><div class="line"></div><div class="line">y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)</div><div class="line"></div><div class="line">cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))</div><div class="line">train_step = tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(cross_entropy)</div><div class="line">correct_prediction = tf.equal(tf.argmax(y_conv, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</div><div class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))</div><div class="line">sess.run(tf.initialize_all_variables())</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20000</span>):</div><div class="line">    batch = mnist.train.next_batch(<span class="number">50</span>)</div><div class="line">    <span class="keyword">if</span> i%<span class="number">100</span> == <span class="number">0</span>:</div><div class="line">        train_accuracy = accuracy.eval(feed_dict=&#123;x:batch[<span class="number">0</span>], y_:batch[<span class="number">1</span>], keep_prob:<span class="number">1.0</span>&#125;)</div><div class="line">        print(<span class="string">"step %d, train accuracy %g"</span> %(i, train_accuracy))</div><div class="line">    train_step.run(feed_dict=&#123;x:batch[<span class="number">0</span>], y_:batch[<span class="number">1</span>], keep_prob:<span class="number">0.5</span>&#125;)</div><div class="line"></div><div class="line">print(<span class="string">"test accuracy %g"</span> %accuracy.eval(feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels, keep_prob: <span class="number">1.0</span>&#125;))</div></pre></td></tr></table></figure></p>
<p>运行结果：<br><img src="http://octtw77pk.bkt.clouddn.com/2017408.png" alt="enter description here"></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://octtw77pk.bkt.clouddn.com/daolu.jpg&quot; alt=&quot;enter description here&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>从零开始的毕设-TensorFlow</title>
    <link href="http://yoursite.com/2017/03/22/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E6%AF%95%E8%AE%BE-TensorFlow%E5%AD%A6%E4%B9%A0%E7%AF%87/"/>
    <id>http://yoursite.com/2017/03/22/从零开始的毕设-TensorFlow学习篇/</id>
    <published>2017-03-22T11:24:21.000Z</published>
    <updated>2017-04-04T08:47:32.315Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://octtw77pk.bkt.clouddn.com/%E8%83%8C%E6%99%AF.jpg" alt="enter description here"></p>
<a id="more"></a>
<h1 id="TensorFlow的安装"><a href="#TensorFlow的安装" class="headerlink" title="TensorFlow的安装"></a>TensorFlow的安装</h1><p>哎，头大，在windows上安装TensorFlow我花了两天才搞定。还不是因为TensorFlow只支持Linux和MacOS。<br>先是尝试了Docker，没成功。然后使用了Anaconda，参考<a href="http://www.jianshu.com/p/08d71a327796" target="_blank" rel="external">这个</a>博客，完成了TensorFlow的安装<br>效果图：<br><img src="http://octtw77pk.bkt.clouddn.com/%E6%88%AA%E5%9B%BE00.png" alt="enter description here"></p>
<h1 id="TensorFlow学习笔记"><a href="#TensorFlow学习笔记" class="headerlink" title="TensorFlow学习笔记"></a>TensorFlow学习笔记</h1><p>照着极客学院的《TensorFlow官方文档中文版》进行学习~~</p>
<h2 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h2><p>TensorFlow基本概念：</p>
<ul>
<li>使用图（graph）来表示计算任务</li>
<li>在被称之为<code>会话（Session）</code>的上下文（context）中执行图。</li>
<li>使用tensor表示数据</li>
<li>通过<code>变量（Variable）</code>维护状态</li>
<li>使用feed和fetch可以为任意的操作赋值或者从其中获取数据</li>
</ul>
<p>TensorFlow是一个编程系统，使用图来表示计算任务，节点称为op，一个op获得0个或多个<code>Tensor</code>，执行计算，产生0个或多个<code>Tensor</code>，每个Tensor是一个类型化的多维数组。图必须在<code>会话</code>里被启动，会话将图的op分发到诸如CPU或GPU之类的设备上，同时提供执行op的方法，这些方法执行后，将产生的tensor返回。<strong>在Python语言中，返回的tensor是numpy <code>ndarray</code>对象</strong></p>
<p><strong>计算图</strong><br>TensorFlow程序通常被组织成一个构建阶段， 在构建阶段，op的执行步骤被描述成一个图，在执行阶段，使用会话执行 执行图中的op<br>例如，通常在构建阶段创建一个图来表示和训练神经网络，然后在执行阶段反复执行图中的训练op</p>
<p><strong>构造图</strong><br><code>常量 constant</code><br>Python库有一个默认图</p>
<blockquote>
<p>构造图<br>import tensorflow as tf<br>matrixl1 = tf.constant([[3., 3.]])<br>matrixl2 = tf.constant([[2.], [2.]])<br>product = tf.matmul(matrixl1, matrixl2)</p>
<p>在一个会话中启动图<br>构造阶段完成后，才能启动图，启动图的第一步是创建换一个Session对象<br>sess = tf.Session()<br>result = sess.run(product)<br>print(result)<br>sess.close()</p>
</blockquote>
<p>Session对象在使用完后需要关闭以释放资源，除了显示调用close外，也可以使用with代码块<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">with tf.Session() as sess:</div><div class="line">	result = sess.run(product)</div><div class="line">	print result</div></pre></td></tr></table></figure></p>
<p><strong>Feed</strong><br>feed机制可以临时代替图中的任意操作中的tensor可以对图中任何操作提交补丁，直接插入一个tensor<br>feed使用一个tensor值临时替换一个操作的输出结果，可以提供feed数据作为run()调用的参数。feed只在调用它的方法内有效，方法结束feed就会消失，最常见的用例是将某些特殊的操作指定为 feed操作，标记的方法是使用tf.placeholder()为这些操作创建占位符</p>
<h2 id="MNIST机器学习入门"><a href="#MNIST机器学习入门" class="headerlink" title="MNIST机器学习入门"></a>MNIST机器学习入门</h2><p><strong>MNIST数据集</strong><br>MNIST的数据集被分为两部分：60000行的训练数据集（mnist.train）和10000行的测试数据集(mnist.test)<br>每一个MNIST数据单元由两部分主城：一张包含手写数字图片和一个对应的标签，我们把这些图片设为<code>xs</code>，把这些标签设为<code>ys</code><br>训练数据集和测试数据集都包含xs和ys<br>训练数据集的图片是mnist.train.images<br>训练数据集的标签是mnist.train.labels<br>每一张图片包含28<em>28个像素点<br>mnist.train.images是一个形状为[60000,784]的张量<br><img src="http://octtw77pk.bkt.clouddn.com/mnist-train-xs.png" alt="enter description here"><br>mnist.train.labels是一个[60000,10]的数字矩阵<br><img src="http://octtw77pk.bkt.clouddn.com/mnist-train-ys.png" alt="enter description here"><br><em>*Softmax回归</em></em><br>Softmax regression模型可以用来给不同的对象分配概率。<br>softmax回归分两步：第一步<br>为了得到一张给定图片属于某个特定数字类的证据，我们对图片像素值进行加权求和。如何这个像素具有很强的证据说明该图片不属于该类，那么相应的权值为负数，相反如果这个像素拥有有利的证据支持这张图片属于这个类，那么权值是正数。</p>
<p>我们也需要加入一个额外的偏置量（bias），因为输入往往会带有一些无关的干扰量。</p>
<p><em>y=softmax(Wx+b)</em></p>
<p><strong>实现回归模型</strong><br>使用TensorFlow之前，首先导入<br><code>import tensorflow as tf</code><br>我们通过操作符变量来描述这些可交互的操作单元<br><code>x = tf.placeholder(tf.float32,[None,784])</code><br>x不是一个特定的值，而是一个占位符，我们在TensorFlow运行计算时输入这个值。我们希望能够输入任意数量的MNIST图像，每一张图展平成784维的向量。我们用2维的浮点数来表示这些图，这个张量的形状是[None，784]（这里的None表示此张量的第一个维度可以是任意长度的）<br>我们的模型也需要权重值和偏置量，当然我们可以把它们当做另外的输入（使用占位符），但TensorFlow有一个更好的方法来表示：Variable。一个Variable代表一个可修改的张量，存在在TensorFlow的用于描述交互性操作的图中。它们可以用于计算输入值，也可以在计算中被修改。对于各种机器学习应用，一把都会有模型参数，可以用Variable表示。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">W = tf.Variable(tf.zeros([784,10]))</div><div class="line">b = tf.Variable(tf.zeros([10]))</div></pre></td></tr></table></figure></p>
<p>W的维度是[784，10]，因为我们想要用784维的图片向量乘以它以得到一个10维的证据值向量，每一位对应不同数字类。<br>b的形状是[10]<br>现在，我们可以实现我们的模型：<br><code>y = tf.nn.softmax(tf.matmul(x,W) + b)</code><br>首先，我们用tf.matmul(x,W)表示x乘以W，对应之前等式的Wx</p>
<p><strong>训练模型</strong><br>为了训练我们的模型，我们首先需要定义一个指标来评估这个模型是好的，这个指标称为成本(cost)或损失(loss)，然后尽量最小化这个指标。<br>一个非常常见非常漂亮的成本函数是“交叉熵“<br><img src="http://octtw77pk.bkt.clouddn.com/mnist10.png" alt=""><br>y是我们预计的概率分布，y’是实际分布。<br>为了计算交叉熵，我们首先需要添加一个新的占位符用于输入正确值：<br><code>y_ = tf.placeholder(&quot;float&quot;, [None,10])</code><br>计算交叉熵：<br><code>cross_entropy = -tf.reduce_sum(y_ * tf.log(y))</code><br>这里的交叉熵不仅仅用来衡量单一的一对预测和真实值，而是所有100幅图片的交叉熵的总和。<br>现在我们知道我们需要我们的模型做什么了，用TensorFlow来训练它是十分容易的。因为TensorFlow拥有一张描述你各个计算单元的图，它可以自动地使用<br><a href="http://colah.github.io/posts/2015-08-Backprop/" target="_blank" rel="external">反向传播算法</a>来有效地确定你的变量是如何影响你想要最小化的那个成本值。然后，TensorFlow会用你选择的优化算法来不断地修改变量以降低成本。</p>
<p><code>train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)</code><br>在这里，我们要求TensorFlow用梯度下降算法（gradient descent algorithm）以0.01的学习速率最小化交叉熵。<br>TensorFlow在这里实际上所做的是，他会在后台给描述你的计算的那张图里面增加一系列新的计算操作单元用于实现反向传播算法和梯度下降算法。然后，它返回给你的只是一个单一的操作,当运行这个操作时，他用梯度下降算法训练你的模型，微调你的变量，不断减少成本。</p>
<p>现在，我们已经设置好了我们的模型，在运行计算之前，我们需要添加一个操作来初始化我们创建的变量：<br><code>init = tf.initialize_all_variables()</code><br>现在我们可以在一个Session里面启动我们的模型，并且初始化变量：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sess = tf.Session()</div><div class="line">sess.run(init)</div></pre></td></tr></table></figure></p>
<p>然后开始训练模型，这里我们让模型循环训练1000次!<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">for i in range(1000):</div><div class="line">	batch_xs, batch_ys = mnist.train.next_batch(100)</div><div class="line">	sess.run(train_step, feed_dict=&#123;x:batch_xs, y_:batch_ys&#125;)</div></pre></td></tr></table></figure></p>
<p>该循环的每个步骤中，我们都会随机抓取训练数据中的100个批处理数据点，然后我们用这些数据点作为参数替换之前的占位符来运行train_step</p>
<p>使用一小部分的随机数据来进行训练被称为随机训练（stochastic training）-在这里更准确的说是随机梯度下降训练。</p>
<p><strong>评估模型</strong><br>首先让我们找出那些预测正确的标签。<code>tf.argmax</code>是一个非常有用的函数，它能给出某个tensor对象在某一维上的其数据最大值所在的索引值。由于标签向量是由0,1组成，因此最大值1所在的索引位置就是类别标签，比如<code>tf.argmax(y,1)</code>返回的是模型对于任一输入x预测到的标签值，而<code>tf.argmax(y_,1)</code>代表正确的标签，我们可以用<code>tf.equal</code>来检测我们的预测是否真实标签匹配（索引位置一样表示匹配）<br><code>correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))</code></p>
<p>这行代码会给我们一组布尔值，为了确定正确预测项的比例，我们可以把布尔值转换成浮点数，然后取平均值。例如，[True，False，True，True]会变成[1,0,1,1]，取平均值然后得到0.75.<br><code>accuracy = tf.reduce_mean(tf.cast(correct_prediction, &quot;float&quot;))</code></p>
<p>最后，我们计算所学习到的模型在测试数据集上面的正确率。<br><code>print sess.run(accuracy, feed_dict={x:mnist.test.images, y_:mnist.test.labels})</code></p>
<p>代码：</p>
<pre><code class="python">
<span class="keyword">import</span> tensorflow.examples.tutorials.mnist.input_data <span class="keyword">as</span> input_data
mnist = input_data.read_data_sets(<span class="string">"MNIST_data/"</span>,one_hot=<span class="keyword">True</span>)

<span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf

<span class="comment">#实现回归模型</span>
x = tf.placeholder(tf.float32, [<span class="keyword">None</span>,<span class="number">784</span>])
W = tf.Variable(tf.zeros([<span class="number">784</span>, <span class="number">10</span>]))
b = tf.Variable(tf.zeros([<span class="number">10</span>]))

y = tf.nn.softmax(tf.matmul(x,W) + b)

<span class="comment">#训练模型</span>
y_ = tf.placeholder(<span class="string">"float"</span>, [<span class="keyword">None</span>, <span class="number">10</span>])
cross_entropy = -tf.reduce_sum(y_ * tf.log(y))

train_step = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>).minimize(cross_entropy)

init = tf.initialize_all_variables()

sess = tf.Session()
sess.run(init)

<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):
    batch_xs, batch_ys = mnist.train.next_batch(<span class="number">100</span>)
    sess.run(train_step, feed_dict={x:batch_xs, y_:batch_ys})

<span class="comment">#评估模型</span>
correct_prediction = tf.equal(tf.argmax(y,<span class="number">1</span>), tf.argmax(y_,<span class="number">1</span>))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, <span class="string">"float"</span>))

<span class="keyword">print</span> (sess.run(accuracy, feed_dict={x:mnist.test.images, y_:mnist.test.labels}))
</code></pre>
<p>结果：<br><img src="http://octtw77pk.bkt.clouddn.com/201744.png" alt="enter description here"></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://octtw77pk.bkt.clouddn.com/%E8%83%8C%E6%99%AF.jpg&quot; alt=&quot;enter description here&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>从零开始的毕设-准备篇</title>
    <link href="http://yoursite.com/2017/03/21/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E6%AF%95%E8%AE%BE-%E5%87%86%E5%A4%87%E7%AF%87/"/>
    <id>http://yoursite.com/2017/03/21/从零开始的毕设-准备篇/</id>
    <published>2017-03-21T10:28:42.000Z</published>
    <updated>2017-04-02T08:17:54.125Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://octtw77pk.bkt.clouddn.com/1080P%20%28193%29.jpg" alt="enter description here"><br><a id="more"></a></p>
<blockquote>
<p>哈哈哈，大四了，即将毕业~~ so，我也迎来了毕业设计的challenge<br>毕业题目：基于深度学习的文字识别系统的设计与实现</p>
</blockquote>
<h1 id="整理了下会用到的知识以及学习目录："><a href="#整理了下会用到的知识以及学习目录：" class="headerlink" title="整理了下会用到的知识以及学习目录："></a>整理了下会用到的知识以及学习目录：</h1><p>1.Python<br>  此前在<strong>Learn Python the Hard Way</strong>学习过Python2.7，不过好像tensorflow会用到Python3.5？到时候再学学3.5吧。。</p>
<p>2.Deep Learning<br>  看博友介绍，打算就这几个教程进行学习：</p>
<ul>
<li><a href="http://neuralnetworksanddeeplearning.com/" target="_blank" rel="external">Neural Networks and Deep Learning</a></li>
<li><p><a href="http://www.deeplearningbook.org/" target="_blank" rel="external">Deep Learning An MIT Press book</a></p>
<p>可能还会用到这个：</p>
</li>
<li><a href="http://deeplearning.stanford.edu/tutorial/" target="_blank" rel="external">模块介绍</a></li>
<li><a href="http://colah.github.io/posts/2014-07-Conv-Nets-Modular/" target="_blank" rel="external">讲卷积神经网络的bolg</a></li>
</ul>
<p>3.TensorFlow<br>  重头戏，可能会用到的学习资料：</p>
<ul>
<li><a href="http://wiki.jikexueyuan.com/project/tensorflow-zh/" target="_blank" rel="external">TensorFlow官方文档中文版</a></li>
<li><a href="http://jorditorres.org/first-contact-with-tensorflow/" target="_blank" rel="external">一个英文网站</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://octtw77pk.bkt.clouddn.com/1080P%20%28193%29.jpg&quot; alt=&quot;enter description here&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="人工智能" scheme="http://yoursite.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>正则表达式和RegExp(JS篇)</title>
    <link href="http://yoursite.com/2016/11/01/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%92%8CRegExp/"/>
    <id>http://yoursite.com/2016/11/01/正则表达式和RegExp/</id>
    <published>2016-11-01T02:12:49.000Z</published>
    <updated>2016-11-07T01:40:28.804Z</updated>
    
    <content type="html"><![CDATA[<h2 id="创建一个正则表达式（regular-expressions）"><a href="#创建一个正则表达式（regular-expressions）" class="headerlink" title="创建一个正则表达式（regular expressions）"></a>创建一个正则表达式（regular expressions）</h2><p>使用正则表达式字面量：<code>var re = /ab+c/;</code><br>使用RegExp对象的构造函数：<code>var re = new RegExp(&quot;ab+c&quot;);</code></p>
<h2 id="编写一个正则表达式的模式"><a href="#编写一个正则表达式的模式" class="headerlink" title="编写一个正则表达式的模式"></a>编写一个正则表达式的模式</h2><p>简单模式：/abc/<br>特殊字符：类似/ab*c/<br><a id="more"></a></p>
<ul>
<li>字符：<code>\</code><br>跟在其后的字符：字面量转义为特殊字符，特殊字符转义为字面量。<br>字面量转义为特殊字符，如<code>/b/</code>意为匹配字符’b’，而<code>/\b/</code>意为匹配一个字符边界<br>特殊字符转为字面量：如<code>/a*/</code>意为匹配0个或者多个a，而<code>/a\*/</code>意为匹配’a*’这样的字符串。<br>使用new RegExp(“pattern”)的时候要将\转义，如字面量模式的<code>/\[bc\]at/</code>等价的字符串为<code>\\[bc\\]at</code>，字面量模式为<code>/\w\\hello\\123/</code>等价的字符串为<code>\\w\\\\hello\\\\123</code></li>
<li>字符：<code>^</code>和<code>$</code><br>匹配输入的开始和结束，如<code>/^A/</code> and <code>/t$/</code></li>
<li>字符：<code>*</code> ， <code>+</code>，<code>?</code><br><em>匹配前一个表达式的0次或多次，+匹配前一个表达式的1次或多次，？匹配前一个表达式的0次或1次<br>**紧跟在任何量词\</em>、+、？的后面，会使量词变得非贪婪（尽可能匹配较少的字符）**</li>
<li>字符：<code>.</code><br>匹配除了换行符（\n）之外的任何单个字符</li>
<li>字符：<code>(x)</code>,<code>(?:x)</code>,<code>x(?=y)</code>,<code>x(?!y)</code><br><code>(x)</code>匹配’x’并且记住匹配项,<code>(?:x)</code>匹配’x’但是不记住匹配项,<code>x(?=y)</code>匹配’x’仅仅当’x’后面跟着’y’，这种叫正向肯定查找，<code>x(?!y)</code>匹配’x’仅仅当后面不跟着’y’，这种叫做正向否定查找</li>
<li>字符：<code>x|y</code><br>匹配’x’或者’y’</li>
<li>字符：<code>{n}</code>,<code>{n.m}</code><br>n是一个正整数，匹配了前面一个字符刚好发生了n次。<br>n和m都是正整数，匹配前面的字符至少出现n次，至多出现m次，如果n和m的值是0，这个值被忽略</li>
<li>字符：<code>[xyz]</code>,<code>[^xyz]</code><br><code>[xyz]</code>一个字符集合，匹配方括号中的任何字符，<code>[^xyz]</code>一个反向字符集 </li>
<li>字符：<code>[\b]</code><br>匹配一个退格</li>
<li>字符：<code>\b</code>,<code>\B</code><br><code>\b</code>匹配一个词的边界,<code>\B</code>匹配一个非单词边界</li>
<li>字符：<code>\d</code>,<code>\D</code><br><code>\d</code>匹配一个数字，等价于[0-9],<code>\D</code>匹配一个非数字字符，等价于[^0-9]</li>
<li>字符<code>\f</code>, <code>\n</code>, <code>\r</code>, <code>\s\</code>,<code>\S\</code>,<code>\t\</code>, <code>\v\</code><br><code>\f</code>匹配一个换页符，<code>\n</code>匹配一个换行符 , <code>\r</code>匹配一个回车符, <code>\s\</code>匹配一个空白字符,<code>\S</code>匹配一个非空白字符，<code>\t\</code>匹配一个水平制表符 , <code>\v\</code>匹配一个垂直制表符</li>
<li>字符：<code>\w</code>,<code>\W</code><br><code>\w</code>匹配一个单字字符（字母、数字或者下划线）。等价于[A-Za-z0-9_]<br><code>\W</code>匹配一个非单字字符。等价于[^A-Za-z0-9]</li>
<li>字符：<code>\n</code><br>当n是一个正整数，返回与n有关的副字符串</li>
<li>字符：<code>\0</code><br>匹配NULL字符，<em>不要在后面跟其他数字，会被转义为其他进制</em></li>
<li>字符<code>\xhh</code>, <code>\uhhhh</code><br><code>\xhh</code>匹配带有两位小数代码 (hh)的字符<br><code>\uhhhh</code>匹配带有思维小数代码(hh)的字符</li>
</ul>
<h2 id="使用正则表达式"><a href="#使用正则表达式" class="headerlink" title="使用正则表达式"></a>使用正则表达式</h2><p>正则表达式可以被用于RegExp的exec和test方法以及String的match、replace、search和split方法。</p>
<blockquote>
<p>test方法、search方法：当你想知道在一个字符串中的一个匹配是否被找到时</p>
<p>exec和match方法：想要得到更多的信息，如果匹配成功，那么这些方法将返回一个数组并且更新相关的正则表达式对象和预定义的正则表达式对象；如果匹配失败，返回null</p>
</blockquote>
<p><strong>实例：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">//使用exec方法在一个字符串中查找一个匹配</div><div class="line">var myRe = /d(b+)d/g;</div><div class="line">var myArray = myRe.exec(&quot;cdbbdbsbz&quot;);</div><div class="line">//如果不需要访问正则表达式的属性，通过下面方法来创建myArray</div><div class="line">var myArray = /d(b+)d/g.exec(&quot;cdbbdbsbz&quot;);</div><div class="line">//通过一个字符串构建正则表达式</div><div class="line">var myRe = new RegExp(&quot;d(b+)d&quot;,&quot;g&quot;);</div><div class="line">var myArray = myRe.exec(&quot;cdbbdbsbz&quot;);</div></pre></td></tr></table></figure></p>
<h3 id="使用括号的子字符串匹配"><a href="#使用括号的子字符串匹配" class="headerlink" title="使用括号的子字符串匹配"></a>使用括号的子字符串匹配</h3><p>正则表达式使用了括号，相应的子匹配会被记住，回调这些括号中匹配的子串，使用数组元素[1]…[n]，$1,$2<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">//使用replace()方法来转换字符串中的单词</div><div class="line">var re = /(w+)\s\(\w+)/;</div><div class="line">var str = &quot;John Smith&quot;;</div><div class="line">var newStr = str.replace(re, &quot;$2,$1&quot;);</div><div class="line">console.log(newStr);  // =&gt; &quot;Smith,John&quot;</div></pre></td></tr></table></figure></p>
<h3 id="通过标志进行高级搜索"><a href="#通过标志进行高级搜索" class="headerlink" title="通过标志进行高级搜索"></a>通过标志进行高级搜索</h3><p>标志:”g”, “i”, “m”, “y”<br>g：全局搜索<br>i：不区分大小写搜索<br>m：多行搜索<br>y：执行“粘性”搜索，匹配从目标字符串的当前位置开始，可以使用y标志</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;创建一个正则表达式（regular-expressions）&quot;&gt;&lt;a href=&quot;#创建一个正则表达式（regular-expressions）&quot; class=&quot;headerlink&quot; title=&quot;创建一个正则表达式（regular expressions）&quot;&gt;&lt;/a&gt;创建一个正则表达式（regular expressions）&lt;/h2&gt;&lt;p&gt;使用正则表达式字面量：&lt;code&gt;var re = /ab+c/;&lt;/code&gt;&lt;br&gt;使用RegExp对象的构造函数：&lt;code&gt;var re = new RegExp(&amp;quot;ab+c&amp;quot;);&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&quot;编写一个正则表达式的模式&quot;&gt;&lt;a href=&quot;#编写一个正则表达式的模式&quot; class=&quot;headerlink&quot; title=&quot;编写一个正则表达式的模式&quot;&gt;&lt;/a&gt;编写一个正则表达式的模式&lt;/h2&gt;&lt;p&gt;简单模式：/abc/&lt;br&gt;特殊字符：类似/ab*c/&lt;br&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="JavaScript" scheme="http://yoursite.com/tags/JavaScript/"/>
    
      <category term="学习笔记" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="正则表达式" scheme="http://yoursite.com/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>谈谈《黑暗之魂1》给我带来的感动</title>
    <link href="http://yoursite.com/2016/09/29/%E8%B0%88%E8%B0%88%E9%BB%91%E6%9A%97%E4%B9%8B%E9%AD%821%E7%BB%99%E6%88%91%E5%B8%A6%E6%9D%A5%E7%9A%84%E6%84%9F%E5%8A%A8/"/>
    <id>http://yoursite.com/2016/09/29/谈谈黑暗之魂1给我带来的感动/</id>
    <published>2016-09-29T11:12:49.000Z</published>
    <updated>2016-10-06T09:03:09.259Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://octtw77pk.bkt.clouddn.com/b7fd5266d01609241e66b6a0dc0735fae7cd34cd.jpg" alt="黑暗之魂1"><br><a id="more"></a><br>《黑暗之魂1》这部作品是我在大三的时候接触的，闻名这是一款超抖M型的硬派RPG游戏，拥有过千小时MH游戏经历的我，自然非常想尝试一下。结果也是38小时<del>轻松</del>通关一周目。</p>
<p>那么，为什么我突然提到这个游戏并写了这篇文章呢，是因为今天在知乎上看到了这样一个问题“最让你震撼的游戏细节有哪些？”我扫了一眼答案，发现居然没有一人提到黑魂1！！这让我非常恼火，这么好的一部作品居然没有被提及！</p>
<p>我很喜欢它的叙事方式和故事内核，有的人玩过黑魂之后说这游戏没有剧情，全是打打杀杀，其实不然，它也拥有着譬如老滚一样庞大的世界观，对它所有的理解都是靠着NPC的只言片语、物品的故事介绍，将这些线索串接起来，你就会理解这竟是描述了一部如此悲壮的故事！要让我说，我觉得黑暗之魂1整部游戏充满着细节，忽视掉这些细节，你可能就成为了一个沉溺于杀戮、丧失人性的不死人，倘若你耐下心来研究，那么游戏中的每一处细节都可能让你感到震撼！</p>
<p>以下，我不打算说游戏中具体的某个小细节，因为这些细节实在太多太多。我就说下，将这些细节拼接起来后让我感到震撼的故事。</p>
<hr>
<blockquote>
<p>“Friend,I have an idea,a good one,really.”<br>“I will rush those dire things and you can slip away in the confusion!”<br>“Please friend,I owe you much more than this.”<br>“By the honour of the Knights of Catarina,allow me to assist you.”<br>“朋友，我有个主意，一个好主意…我会吸引这些怪物的注意力，你趁乱逃出去!拜托了，朋友，我欠你的太多太多。以卡特里纳骑士的荣誉之名，请允许我来帮助你!” ——洋葱骑士杰格迈尔<br><img src="http://octtw77pk.bkt.clouddn.com/b8f4cacec3fdfc036e6d8424d23f8794a4c22619.jpg" alt=""></p>
</blockquote>
<p>杰格迈尔是黑魂1里人气很高的角色，因为穿着的铠甲极其像一个洋葱，所以人称洋葱骑士，哈哈。他呆萌呆萌的，还老是犯傻遇到问题，让人忍不住想帮助他。<br>这里，有一个设定是当一个不死人失去所有希望时，他们就会开始活尸化，洋葱骑士是一个勇敢的探险者，热衷于冒险的激情使他与活尸化无缘，“Siegmeyer”这个名字代表着胜利，而胜利就是他的人生价值所在。<br>在游戏中，我们能遇到好多次洋葱骑士，每次遇到他，他似乎都遇到了困难，被古城拦在外头，被皇城的骑手吓得瑟瑟发抖等等。出于好意，我们一次又一次的帮助了他，但是殊不知我们的好意其实是在无形中慢慢剥夺他引以为傲的一切，让他觉得他得靠其他人渡过难关，我们的每一次帮助其实都在摧毁他的自信心，我们的每一次帮助都使他离活尸化越来越近。在废都那儿，他终于下定决心准备最后一搏，以牺牲自己来报答朋友，可是我们连他最后的尊严与胜利也剥夺了，如果我们选择让他牺牲自己来掩护我们逃跑，那么他将带着荣耀死去，然而，再一次拯救他，再一次侮辱了他的自尊…这也是我们最后一次见到活着的洋葱骑士了，在隐藏地图灰烬湖，我们找到了洋葱骑士，可是这时的他已被他的女儿忍痛杀害了，他女儿的使命就是寻找自己的父亲，然后在他活尸化后将他杀害，避免他滥杀无辜。我们的朋友，在灰烬图走到了人生的终点。</p>
<hr>
<blockquote>
<p>“Why?….Why?…..”<br>“After all these searching,I still cannot find it.”<br>“Was it all a lie?Have I done this all for nothing?”<br>“为什么？…为什么?….我经历了如此漫长的求索，为什么还是找不到。这一切都是谎言吗？我做的一切都毫无意义吗？”——太阳骑士索拉尔<br><img src="http://octtw77pk.bkt.clouddn.com/201505071709269013945.jpg" alt=""></p>
</blockquote>
<p>太阳骑士是我们的好基友，很多BOSS都可以抱他的大腿，登场的姿势成为了一种潮流(大误)。<br>正义的太阳骑士与主角有着不说清的关系，他们的命运似乎紧密的交错在一起，同是不死人，同样被囚禁在不死院，最后同样来到了太阳祭坛，搭上了同样的旅途…索拉尔的理想是在罗德兰寻找太阳，寻求光明，他不介意像个傻子一样，付诸一切来追寻梦想，然而这片大陆早已陷入黑暗，这旅途注定是挫折的。<br>随着游戏的推进，我们和他的羁绊也越来越强烈。在游戏中后期，当我们在恶魔遗迹发现他被太阳虫洗脑时，我们的内心一定是绝望的T^T。在多年的找寻无果后，他的希望终于变成了绝望，他输给了一种长得像太阳的虫子，并死在了我们的剑下。（有一个小细节，击杀太阳骑士后拿到他的盔甲，物品描述竟然是非常普通的盔甲，甚至衣服上太阳的标志都是自己画上去的，多么单纯善良的一个人。）<br>然而，我们怎么能让他就这么死去！在网上大牛的探索下，发现了避免太阳骑士被洗脑的方法，向白蜘蛛献出30个人性，开出捷径，杀光太阳虫，拯救太阳骑士！<br>在最终章初始的火炉，我们可以召唤太阳骑士与他并肩作战对抗葛温，击败葛温后，太阳骑士终于可以实现自己的梦想了T^T，将燃烧了自己的身体，让太阳重回大地，他心中的火，将会比世间万物都要闪耀！</p>
<hr>
<blockquote>
<p>“[coughs]All of you…..forgive me,for I have availed you nothing.”<br>“大家…..原谅我，我什么都没能做到。”——亚尔特留斯</p>
</blockquote>
<p>额，想偷懒了…就放些图吧，帅气的A大</p>
<p><img src="http://octtw77pk.bkt.clouddn.com/vXd2Ky8.jpg" alt="A大"><br>一直守护着自己逝去的战友的巨狼希夫</p>
<p><img src="http://octtw77pk.bkt.clouddn.com/QTbzHB4.jpg" alt="巨狼希夫"><br>当我们先打DLC再去找黑庭院森林找它，就会触发隐藏剧情。本应该立马攻击入侵者的希夫，却停下来凝视你，它记得你，知道你来的目的，但是他不能让你拿到能够漫步深渊的戒指，它为了保护你唯有继续战斗…希夫扬天长啸，叼起了亚尔特留斯的巨剑….(有个细节，与上一次不同，这里希夫叼的剑是朝左的，是故意拿出钝面来战斗)</p>
<p><img src="http://octtw77pk.bkt.clouddn.com/OcYvm3h.jpg" alt="死亡凝视"></p>
<p><img src="http://octtw77pk.bkt.clouddn.com/%E6%88%AA%E5%9B%BE02.png" alt=""></p>
<hr>
<p><em>如果你又倒下了，请再次站起来，这就是不死人的赞歌。重要的不是生或死，而是谁先倒下，是你的信念，还是阻挡你的障碍，每个人都要面对自己的命运。</em></p>
<hr>
<p>最后，例行惯例，<strong>赞美太阳</strong> \(^o^)/~</p>
<p>附上知乎链接，喜欢这篇文章的小伙伴可以给我点个赞~~<br><a href="https://www.zhihu.com/question/49642449/answer/124347294?group_id=767402549652238336" target="_blank" rel="external">传送门</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://octtw77pk.bkt.clouddn.com/b7fd5266d01609241e66b6a0dc0735fae7cd34cd.jpg&quot; alt=&quot;黑暗之魂1&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="随笔" scheme="http://yoursite.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="随笔，游戏" scheme="http://yoursite.com/tags/%E9%9A%8F%E7%AC%94%EF%BC%8C%E6%B8%B8%E6%88%8F/"/>
    
  </entry>
  
  <entry>
    <title>OJ集中营</title>
    <link href="http://yoursite.com/2016/09/16/OJ%E9%9B%86%E4%B8%AD%E8%90%A5/"/>
    <id>http://yoursite.com/2016/09/16/OJ集中营/</id>
    <published>2016-09-16T01:55:16.000Z</published>
    <updated>2016-09-16T01:57:32.705Z</updated>
    
    <content type="html"><![CDATA[<p>leetcode解题集：<a href="https://github.com/SiriusHsh/leetcode" target="_blank" rel="external">https://github.com/SiriusHsh/leetcode</a><br>PAT解题集：<a href="https://github.com/SiriusHsh/PAT" target="_blank" rel="external">https://github.com/SiriusHsh/PAT</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;leetcode解题集：&lt;a href=&quot;https://github.com/SiriusHsh/leetcode&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/SiriusHsh/leetcode&lt;/a&gt;&lt;br&gt;P
    
    </summary>
    
      <category term="OJ" scheme="http://yoursite.com/categories/OJ/"/>
    
    
      <category term="算法" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="Java" scheme="http://yoursite.com/tags/Java/"/>
    
      <category term="C++" scheme="http://yoursite.com/tags/C/"/>
    
      <category term="JavaScript" scheme="http://yoursite.com/tags/JavaScript/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Windows通过cmd查看端口占用杀死进程的命令</title>
    <link href="http://yoursite.com/2016/09/07/Windows%E9%80%9A%E8%BF%87cmd%E6%9F%A5%E7%9C%8B%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8%E6%9D%80%E6%AD%BB%E8%BF%9B%E7%A8%8B%E7%9A%84%E5%91%BD%E4%BB%A4/"/>
    <id>http://yoursite.com/2016/09/07/Windows通过cmd查看端口占用杀死进程的命令/</id>
    <published>2016-09-07T07:53:17.000Z</published>
    <updated>2016-09-07T07:57:54.138Z</updated>
    
    <content type="html"><![CDATA[<p>最近运行<code>hexo s</code>的时候有时候会遇到4000端口被占用的情况，记录一下杀死占用4000端口进程的过程。</p>
<ol>
<li><code>netstat -ano</code>查看所有进程，<code>netstat -ano|findstr &quot;4000&quot;</code>查看4000端口的情况。</li>
<li>这时候能获取到进程的PID，打开任务管理器找到该进程杀死即可。(没有显示PID的情况：查看 -&gt; 选择列 -&gt; 勾选PID)</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近运行&lt;code&gt;hexo s&lt;/code&gt;的时候有时候会遇到4000端口被占用的情况，记录一下杀死占用4000端口进程的过程。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;netstat -ano&lt;/code&gt;查看所有进程，&lt;code&gt;netstat -ano|findstr
    
    </summary>
    
      <category term="问题解决" scheme="http://yoursite.com/categories/%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"/>
    
    
      <category term="Windows" scheme="http://yoursite.com/tags/Windows/"/>
    
      <category term="Hexo" scheme="http://yoursite.com/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>解决Powershell无法进入名字中带空格的路径</title>
    <link href="http://yoursite.com/2016/09/07/%E8%A7%A3%E5%86%B3Powershell%E6%97%A0%E6%B3%95%E8%BF%9B%E5%85%A5%E5%90%8D%E5%AD%97%E4%B8%AD%E5%B8%A6%E7%A9%BA%E6%A0%BC%E7%9A%84%E8%B7%AF%E5%BE%84/"/>
    <id>http://yoursite.com/2016/09/07/解决Powershell无法进入名字中带空格的路径/</id>
    <published>2016-09-07T00:55:59.000Z</published>
    <updated>2016-09-07T01:01:27.929Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://octtw77pk.bkt.clouddn.com/%E6%88%AA%E5%9B%BE05.png" alt="图片"><br>解决：使用命令<code>Push-Location -Path &quot;Sublime Text 3&quot;</code><img src="http://octtw77pk.bkt.clouddn.com/%E6%88%AA%E5%9B%BE03.png" alt="图片"></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://octtw77pk.bkt.clouddn.com/%E6%88%AA%E5%9B%BE05.png&quot; alt=&quot;图片&quot;&gt;&lt;br&gt;解决：使用命令&lt;code&gt;Push-Location -Path &amp;quot;Sublime Text 3&amp;q
    
    </summary>
    
      <category term="问题解决" scheme="http://yoursite.com/categories/%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"/>
    
    
      <category term="Sublime Text 3" scheme="http://yoursite.com/tags/Sublime-Text-3/"/>
    
  </entry>
  
  <entry>
    <title>解决JNI相关问题(3)</title>
    <link href="http://yoursite.com/2016/09/04/%E8%A7%A3%E5%86%B3JNI%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98(3)/"/>
    <id>http://yoursite.com/2016/09/04/解决JNI相关问题(3)/</id>
    <published>2016-09-04T10:17:30.000Z</published>
    <updated>2016-09-04T10:25:00.110Z</updated>
    
    <content type="html"><![CDATA[<h3 id="解决问题：Can’t-find-dependent-libraries报错"><a href="#解决问题：Can’t-find-dependent-libraries报错" class="headerlink" title="解决问题：Can’t find dependent libraries报错"></a>解决问题：Can’t find dependent libraries报错</h3><a id="more"></a>
<p>今天将项目移植到另外一台电脑上，结果JNI又出错了，<del>真是一个柔弱的女子啊</del></p>
<p>解决思路：无法找到依赖的库,应该是.dll出的问题</p>
<p>解决方案：将编译方案由Debug改为Release，解决！</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;解决问题：Can’t-find-dependent-libraries报错&quot;&gt;&lt;a href=&quot;#解决问题：Can’t-find-dependent-libraries报错&quot; class=&quot;headerlink&quot; title=&quot;解决问题：Can’t find dependent libraries报错&quot;&gt;&lt;/a&gt;解决问题：Can’t find dependent libraries报错&lt;/h3&gt;
    
    </summary>
    
      <category term="问题解决" scheme="http://yoursite.com/categories/%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"/>
    
    
      <category term="Java" scheme="http://yoursite.com/tags/Java/"/>
    
      <category term="JNI" scheme="http://yoursite.com/tags/JNI/"/>
    
  </entry>
  
  <entry>
    <title>解决JNI相关问题(2)</title>
    <link href="http://yoursite.com/2016/09/04/%E8%A7%A3%E5%86%B3JNI%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98(2)/"/>
    <id>http://yoursite.com/2016/09/04/解决JNI相关问题(2)/</id>
    <published>2016-09-04T09:20:40.000Z</published>
    <updated>2016-09-04T10:25:11.222Z</updated>
    
    <content type="html"><![CDATA[<h3 id="本篇主要讲述JNI中GetStringUTFChars-方法的用法。"><a href="#本篇主要讲述JNI中GetStringUTFChars-方法的用法。" class="headerlink" title="本篇主要讲述JNI中GetStringUTFChars()方法的用法。"></a>本篇主要讲述JNI中GetStringUTFChars()方法的用法。</h3><a id="more"></a>
<p>Java中有String类型，对应JNI中的JString，而C语言中没有这种类型，GetStringUTFChars()这个方法就是用来将JString转换成C语言中的char *类型的。</p>
<p>该函数有两种形式：</p>
<ol>
<li><strong>C中的形式</strong><br>C代码：<code>const char *str = (*env)-&gt;GetStringUTFChars(env,string,0)</code></li>
<li><strong>C++中的形式</strong><br>C++代码:<code>const char *str = env-&gt;GetStringUTFChars(string,0)</code></li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;本篇主要讲述JNI中GetStringUTFChars-方法的用法。&quot;&gt;&lt;a href=&quot;#本篇主要讲述JNI中GetStringUTFChars-方法的用法。&quot; class=&quot;headerlink&quot; title=&quot;本篇主要讲述JNI中GetStringUTFChars()方法的用法。&quot;&gt;&lt;/a&gt;本篇主要讲述JNI中GetStringUTFChars()方法的用法。&lt;/h3&gt;
    
    </summary>
    
      <category term="问题解决" scheme="http://yoursite.com/categories/%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"/>
    
    
      <category term="Java" scheme="http://yoursite.com/tags/Java/"/>
    
      <category term="JNI" scheme="http://yoursite.com/tags/JNI/"/>
    
  </entry>
  
  <entry>
    <title>解决JNI相关问题(1)</title>
    <link href="http://yoursite.com/2016/09/04/%E8%A7%A3%E5%86%B3JNI%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98(1)/"/>
    <id>http://yoursite.com/2016/09/04/解决JNI相关问题(1)/</id>
    <published>2016-09-04T02:54:31.000Z</published>
    <updated>2016-09-04T13:34:41.183Z</updated>
    
    <content type="html"><![CDATA[<h2 id="本篇主要讲述："><a href="#本篇主要讲述：" class="headerlink" title="本篇主要讲述："></a>本篇主要讲述：</h2><ul>
<li>生成.h文件的正确姿势</li>
<li>生成和使用.dll文件的正确姿势</li>
</ul>
<a id="more"></a>
<blockquote>
<p>最近着手的项目用到了JNI，照着文档边学边做，遇到了很多坑，我打算一一写出来，来帮助也遇到JNI相关问题的童鞋。<br><del>国内资料实在是太渣了，让我绕了好多弯路</del></p>
</blockquote>
<h3 id="如何生成-h文件"><a href="#如何生成-h文件" class="headerlink" title="如何生成.h文件"></a>如何生成.h文件</h3><p>首先编写好Java程序(有关JNI的Java程序写法不详述了)<img src="http://octtw77pk.bkt.clouddn.com/9/4JNI.png" alt="图片">在该文件所在的目录下按<code>shift+右键</code>,打开命令行，输入<code>javac your_file_name.java</code>编译成.class文件。</p>
<hr>
<p>上面都是小儿科，关键来了，退出到<strong>该Java文件的包的同一级</strong>，为什么意思呢，拿我这个Java文件来说，它有包名<code>com.jg.model.Image</code>所以应该退出到<img src="http://octtw77pk.bkt.clouddn.com/%E6%88%AA%E5%9B%BE06.png" alt="图片">这一级，能看到com包，打开命令行输入<code>javah your_file_name</code>来生成.h文件，格式为： javah 包名.文件名，这里有两点要提：1.包名一定要写全 2.文件名后没有后缀!参考我这个写法：<img src="http://octtw77pk.bkt.clouddn.com/%E6%88%AA%E5%9B%BE07.png" alt="图片">前面都操作正确，就能见到这个.h文件了<img src="http://octtw77pk.bkt.clouddn.com/%E6%88%AA%E5%9B%BE08.png" alt="图片"></p>
<hr>
<h3 id="如何生成和使用-dll文件"><a href="#如何生成和使用-dll文件" class="headerlink" title="如何生成和使用.dll文件"></a>如何生成和使用.dll文件</h3><p>之后就是打开C/C++的IDE来编写C/C++程序，这里我使用的是VS2013。<br>这里我也遇到了好多问题，我来写一下我的解决方案吧。<br>打开VS2013，文件–&gt;新建–&gt;项目–&gt;Win32控制台应用程序（<strong>项目名字要注意，是你在Java程序里写的要加载的库名,即System.loadLibrary(“”)里写的库名</strong>）–&gt;确定–&gt;下一步–&gt;<strong>应用程序类型</strong>选择DLL，点上空项目–&gt;完成–&gt;源程序里创建一个cpp开始编写，之后我不着重讲怎么写C程序)(因为很简单)，而是来讲下你们可能会出现的一些问题：</p>
<ul>
<li><strong>头文件引入问题</strong><br>如果头文件引入不当，会出现五花八门的错误，我来讲下我的做法：将上面编译出的.h文件放到和源程序（上一步创建用来编写程序的那个cpp）一起，之后还有两个.h文件，分别是jni.h，位于<code>%HOME%\Java\jdk1.8.0_71\include</code>, jni-md.h，位于<code>%HOME%\Java\jdk1.8.0_71\include\win32</code>，把这两也放到和源程序一起，<img src="http://octtw77pk.bkt.clouddn.com/%E6%88%AA%E5%9B%BE09.png" alt="图片">然后在VS里点头文件-&gt;添加现有项，将那三个头文件加进去，这时你会发现你自个儿的那个头文件报错了，没事，将<code>#include &lt;jni.h&gt;</code> 改成 <code>#include &quot;jni.h&quot;</code>，现在去看看，应该没有报错了~~</li>
<li><strong>dll应该放哪儿？</strong><br>好不容易生成了.dll，应该放哪儿了呢？它应该被放在两个地方，一个是项目的根目录，一个是eclipse的根目录(我用的是eclipse，intelliJ不清楚)。<del>可能需要把eclipse重启下</del></li>
<li><strong>用win32编译问题</strong><br>你以为这问题结束了？并没有！由于我们大多使用的是64位的jdk，而VS默认使用的win32的解决方案，所以我们好不容易生成的.dll是不起作用的，不过别怕，只要稍作修改就就能解决~~<br>打开VS的配置管理器，修改成如下图所示:<img src="http://octtw77pk.bkt.clouddn.com/%E6%88%AA%E5%9B%BE11.png" alt="图片"><img src="http://octtw77pk.bkt.clouddn.com/%E6%88%AA%E5%9B%BE12.png" alt="图片">重新生成一下解决方案，用新生成的dll替换之前的那两个dll（新生成的dll在<code>/项目根目录/x64/debug</code>中）<br>如果出现<code>error LNK1561: 必须定义入口点</code>,那么这样来：右键项目–&gt;属性–&gt;常规–&gt;配置类型–&gt;动态库(.dll) </li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>到这里你应该看到你的JNI跑起来了，尽情去玩耍她吧！！<br><img src="http://octtw77pk.bkt.clouddn.com/%E6%88%AA%E5%9B%BE10.png" alt="图片"></p>
<hr>
<p>最后附上我此前没讲的C++程序的写法<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"com_jg_model_Image_TestJNI.h"</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</div><div class="line"><span class="function">JNIEXPORT <span class="keyword">void</span> JNICALL <span class="title">Java_com_jg_model_Image_TestJNI_sayHello</span></span></div><div class="line"><span class="params">(JNIEnv *, jclass)</span></div><div class="line">&#123;</div><div class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"Hello World!"</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;本篇主要讲述：&quot;&gt;&lt;a href=&quot;#本篇主要讲述：&quot; class=&quot;headerlink&quot; title=&quot;本篇主要讲述：&quot;&gt;&lt;/a&gt;本篇主要讲述：&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;生成.h文件的正确姿势&lt;/li&gt;
&lt;li&gt;生成和使用.dll文件的正确姿势&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="问题解决" scheme="http://yoursite.com/categories/%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"/>
    
    
      <category term="JNI" scheme="http://yoursite.com/tags/JNI/"/>
    
      <category term="JAVA" scheme="http://yoursite.com/tags/JAVA/"/>
    
  </entry>
  
  <entry>
    <title>Git学习笔记</title>
    <link href="http://yoursite.com/2016/08/30/Git%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2016/08/30/Git学习笔记/</id>
    <published>2016-08-30T12:05:16.000Z</published>
    <updated>2016-09-16T01:09:18.810Z</updated>
    
    <content type="html"><![CDATA[<h1 id="创建版本库"><a href="#创建版本库" class="headerlink" title="创建版本库"></a>创建版本库</h1><p>1.初始化Git仓库，使用<code>git init</code>命令　　<br>2.添加文件到Git仓库，分两步：<br>　　第一步,使用命令<code>git add &lt;file&gt;</code>，注意，可反复多次使用，添加多个文件<br>　　第二步,使用命令<code>git commit</code>,完成<br>　　//两步合一步，<code>git commit -am &quot;&quot;</code>….. 仅适用于修改文件，如果有新文件添加，还是需要两步<br>3.要随时掌握工作区的状态，使用 <code>git status</code>命令<br><a id="more"></a></p>
<h1 id="本地仓库管理"><a href="#本地仓库管理" class="headerlink" title="本地仓库管理"></a>本地仓库管理</h1><p>1.如果 <code>git status</code>告诉你有文件被修改过，用<code>git diff</code>可以查看修改内容<br>2.HEAD指向的版本就是当前的版本，因此，Git允许我们在版本的历史之间穿梭，使用命令 <code>git reset --hard commit_id</code><br>        　　git reset –hard HEAD^<br>    　　git reset –hard HEAD^^…<br>    　　git reset –hard HEAD~100<br>3.穿梭前，使用 <code>git log</code>    (git log –pretty=oneline –abbrev-commmit)<br>4.要重返未来，用 <code>git reflog</code>查看命令历史，以便确定要回到未来的哪个版本<br>5.工作区(Working Directory)就是在电脑里能看到的目录<br>　　版本库(Repository) 工作区有一个隐藏目录 .git，这就是Git的版本库<br>　　版本库里存了很多东西，其中最重要的就是stage的暂存区，还有Git为我们自动创建的第一个分支master，以及指向master的一个指针HEAD<br>6.Git跟踪并管理的是修改，而非文件，每次修改，如果不add到暂存区，那就不会加入到commit中<br>7.撤销修改<br>   　　场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令<code>git checkout -- fileName</code><br>   　　场景2：当你不仅改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃，分两步<br>　　　　第一步，用命令<code>git reset HEAD fileName</code>，就回到了场景1<br>　　　　第二步，按场景1操作<br>　　场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，参考版本回退<br>8.对应的，删除文件<br>    　　场景1,仅删除了工作区里的文件,rm fileName,那么用命令 <code>git checkout -- fileName</code>来恢复 (实际就是stage  –&gt; Wording Directory)<br>    　　场景2，删除了文件又提交到了stage, <code>git rm fileName</code>, 那么也是分两步        　　<br>　　　　　第一步，用命令<code>git reset HEAD fileName</code>，回到场景1         　　<br>　　　　　第二步，按场景1操作<br>    　　场景3：已经提交了删除操作到版本库，想要撤销本次删除，参考版本回退</p>
<h1 id="远程仓库"><a href="#远程仓库" class="headerlink" title="远程仓库"></a>远程仓库</h1><p>1.github相关,git如何将github作为远程仓库呢<br>　　(1) of course,注册一个Github账号<br>　　(2) 创建SSH Key   中文测试<br>　　<code>ssh-keygen -t rsa -C &quot;youremail@example.com&quot;</code><br>　　地址：用户主目录, .ssh目录， id_rsa是私钥，id_rsa.pub是公钥<br>　　(3)登录Github，打开 “Account settings”,”SSH Keys”页面，点“Add SSH Key“，<br>　　填上title，在key文本中粘贴id_rssa.pub文件的内容<br>2.要关联一个远程库，使用命令 <code>git remote add origin git@github.com:userName/repo-name.git</code><br>        关联后，使用命令 <code>git push -u origin master</code> 第一次推送master分支的所有内容<br>        此后，每次本地提交后，可以使用 <code>git push origin master</code>推送最新修改<br>3.要克隆一个仓库，首先必须知道仓库的地址，然后使用 git clone命令克隆<br>　　Git支持多种协议，包括https，但是ssh支持的原生git协议速度最快<br>　　<code>git clone https://github.com/SiriusHsh/gitskills.git</code><br>　　<code>git clone git@github:SiriusHsh/gitskills.git</code></p>
<h1 id="分支管理"><a href="#分支管理" class="headerlink" title="分支管理"></a>分支管理</h1><p>1.分支操作：<br>　　查看分支：<code>git branch</code><br>　　创建分支：<code>git branch branchName</code><br>　　切换分支：<code>git checkout branchName</code>　<br>　　创建+切换分支: <code>git checkout -b branchName</code><br>　　合并某分支到当前分支：<code>git merge branchName</code><br>　　删除分支：<code>git branch -d branchName</code><br>2.当Git无法自动合并分支时，就必须首先解决冲突。解决冲突后，在提交，合并完后才能使用 <code>git log --graph --pretty=oneline --abbrev-commit</code>命令可以看到分支合并图<br>3.合并分支时，加上 –no-ff 参数就可以用普通模式合并，合并后的历史有分支，能看出来曾经做过合并<br>而fast forward合并就看不出曾经做过合并.<br>      <code>git merge --no-ff -m &quot;XXX&quot;</code><br>4.BUG分支与保存现场<br>　　修复bug时，我们会通过创建新的bug分支进行修复，然后合并，最后删除<br>　　当手头工作没有完成时，先把工作现场 <code>git stash</code>一下，然后去修复bug，修复后，再<code>git stash pop</code>,回到现场<br><code>git stash list</code>，可以查看有哪些工作现场<br>　　修复现场有两种方法<br>　　　　一是用<code>git stash apply</code>修复，但是恢复后，stash内容并不删除，需用<code>git stash drop</code>来删除<br>　　　　二是用<code>git stash pop</code>，恢复的同时把stash的内容也删除了。<br>5.feature分支<br>　　开发一个新feature，最好新建一个分支<br>　　如果要丢弃一个没有被合并过的分支，可以通过<code>git checkout -D branchName</code><br>6.查看远程库信息,使用<code>git remote -v</code><br>7.多人协作的工作模式<br>　　(1)首先，可以试图用<code>git push origin branchName</code>推送自己的修改<br>　　(2)如果推送失败，则因为远程分支比你的本地更新，需要先用<code>git pull</code>试图合并<br>　　(3)如果合并有冲突，则解决冲突，并在本地提交<br>　　(4)没有冲突或者解决掉冲突后，再用 <code>git push origin branchName</code> 推送就能成功！<br>　　如果 <code>git pull</code> 提示“no tracking information“，则说明本地分支和远程分支的链接关系没有创建，<br>　　用命令 <code>git branch --set-upstream branchName origin/branchName</code></p>
<h1 id="标签管理"><a href="#标签管理" class="headerlink" title="标签管理"></a>标签管理</h1><p>1.创建标签<br>　　命令<code>git tag tagName</code>用于新建一个标签，默认为HEAD，也可以指定一个commit id<br>　　git tag -a tagName -m “XXXXX”  可以指定标签信息，-a 指定标签签名，-m指定说明文字<br>　　git tag -s tagName -m “XXXXX”  可以用PGP签名标签<br>　　命令git tag可以查看所有标签<br>2.操作标签<br>　　命令<code>git push origin tagName</code> 可以推送一个本地标签<br>　　命令<code>git push origin --tags</code>可以推送全部未推送过的本地标签<br>　　命令<code>git tag -d tagName</code> 可以删除一个本地标签　　<br>　　命令<code>git push origin :refs/tags/tagName</code> 可以删除一个远程标签</p>
<h1 id="自定义Git"><a href="#自定义Git" class="headerlink" title="自定义Git"></a>自定义Git</h1><p>1.忽略特殊文件<br>　　忽略某些文件时，需要编写.gitignore<br>　　.gitignore文件本身要放到版本库里，并且可以对.gitignore做版本管理<br>2.配置别名<br><code>git config --global alias.co checkout</code><br><code>git config --global alias.ci commit</code><br><code>git config --global alias.br branch</code></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;创建版本库&quot;&gt;&lt;a href=&quot;#创建版本库&quot; class=&quot;headerlink&quot; title=&quot;创建版本库&quot;&gt;&lt;/a&gt;创建版本库&lt;/h1&gt;&lt;p&gt;1.初始化Git仓库，使用&lt;code&gt;git init&lt;/code&gt;命令　　&lt;br&gt;2.添加文件到Git仓库，分两步：&lt;br&gt;　　第一步,使用命令&lt;code&gt;git add &amp;lt;file&amp;gt;&lt;/code&gt;，注意，可反复多次使用，添加多个文件&lt;br&gt;　　第二步,使用命令&lt;code&gt;git commit&lt;/code&gt;,完成&lt;br&gt;　　//两步合一步，&lt;code&gt;git commit -am &amp;quot;&amp;quot;&lt;/code&gt;….. 仅适用于修改文件，如果有新文件添加，还是需要两步&lt;br&gt;3.要随时掌握工作区的状态，使用 &lt;code&gt;git status&lt;/code&gt;命令&lt;br&gt;
    
    </summary>
    
      <category term="学习记录" scheme="http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"/>
    
    
      <category term="学习笔记" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="Git" scheme="http://yoursite.com/tags/Git/"/>
    
      <category term="Github" scheme="http://yoursite.com/tags/Github/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2016/08/29/hello-world/"/>
    <id>http://yoursite.com/2016/08/29/hello-world/</id>
    <published>2016-08-28T16:00:00.000Z</published>
    <updated>2016-09-03T13:40:22.912Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><a id="more"></a>
<h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for more info. If you get any problems when using Hexo, you can find the answer in &lt;a href=&quot;https://hexo.io/docs/troubleshooting.html&quot;&gt;troubleshooting&lt;/a&gt; or you can ask me on &lt;a href=&quot;https://github.com/hexojs/hexo/issues&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;Quick-Start&quot;&gt;&lt;a href=&quot;#Quick-Start&quot; class=&quot;headerlink&quot; title=&quot;Quick Start&quot;&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;
    
    </summary>
    
      <category term="博客搭建" scheme="http://yoursite.com/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="博客" scheme="http://yoursite.com/tags/%E5%8D%9A%E5%AE%A2/"/>
    
  </entry>
  
</feed>
